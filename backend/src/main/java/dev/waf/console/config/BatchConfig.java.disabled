package dev.waf.console.config;

import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.batch.core.Job;
import org.springframework.batch.core.Step;
import org.springframework.batch.core.configuration.annotation.EnableBatchProcessing;
import org.springframework.batch.core.job.builder.JobBuilder;
import org.springframework.batch.core.launch.support.RunIdIncrementer;
import org.springframework.batch.core.repository.JobRepository;
import org.springframework.batch.core.step.builder.StepBuilder;
import org.springframework.batch.item.ItemProcessor;
import org.springframework.batch.item.ItemReader;
import org.springframework.batch.item.ItemWriter;
import org.springframework.batch.item.data.RepositoryItemReader;
import org.springframework.batch.item.data.RepositoryItemWriter;
import org.springframework.batch.item.data.builder.RepositoryItemReaderBuilder;
import org.springframework.batch.item.data.builder.RepositoryItemWriterBuilder;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.data.domain.Sort;
import org.springframework.scheduling.annotation.EnableScheduling;
import org.springframework.scheduling.annotation.Scheduled;
import org.springframework.transaction.PlatformTransactionManager;

import java.time.LocalDateTime;
import java.util.Collections;

/**
 * Spring Batch 설정
 *
 * 대용량 데이터 처리를 위한 배치 작업:
 * - 로그 데이터 정리 및 아카이브
 * - 통계 데이터 집계
 * - 보고서 생성
 * - 오래된 데이터 삭제
 * - 알림 이력 정리
 * - 캐시 데이터 동기화
 *
 * 배치 작업 유형:
 * 1. 일일 정리 작업 (로그, 세션 정리)
 * 2. 주간 집계 작업 (통계, 리포트)
 * 3. 월간 아카이브 작업 (장기 보관)
 * 4. 실시간 스트림 처리 (Kafka 연동)
 *
 * @author WAF Console Team
 * @since 2.0.0
 */
@Slf4j
@Configuration
@EnableBatchProcessing
@EnableScheduling
@RequiredArgsConstructor
public class BatchConfig {

    private final JobRepository jobRepository;
    private final PlatformTransactionManager transactionManager;

    // Repository 의존성 (실제 구현에서는 주입받아 사용)
    // private final AttackLogRepository attackLogRepository;
    // private final AccessLogRepository accessLogRepository;
    // private final AuditLogRepository auditLogRepository;

    /**
     * 로그 정리 작업 (일일 실행)
     */
    @Bean
    public Job logCleanupJob() {
        return new JobBuilder("logCleanupJob", jobRepository)
            .incrementer(new RunIdIncrementer())
            .listener(new JobExecutionListener())
            .flow(oldLogDeletionStep())
            .next(logArchiveStep())
            .next(statisticsUpdateStep())
            .end()
            .build();
    }

    /**
     * 오래된 로그 삭제 스텝
     */
    @Bean
    public Step oldLogDeletionStep() {
        return new StepBuilder("oldLogDeletionStep", jobRepository)
            .tasklet(new OldLogDeletionTasklet(), transactionManager)
            .build();
    }

    /**
     * 로그 아카이브 스텝
     */
    @Bean
    public Step logArchiveStep() {
        return new StepBuilder("logArchiveStep", jobRepository)
            .<LogData, ArchivedLogData>chunk(1000, transactionManager)
            .reader(logDataReader())
            .processor(logArchiveProcessor())
            .writer(archivedLogDataWriter())
            .faultTolerant()
            .retryLimit(3)
            .retry(Exception.class)
            .skipLimit(10)
            .skip(Exception.class)
            .build();
    }

    /**
     * 통계 업데이트 스텝
     */
    @Bean
    public Step statisticsUpdateStep() {
        return new StepBuilder("statisticsUpdateStep", jobRepository)
            .tasklet(new StatisticsUpdateTasklet(), transactionManager)
            .build();
    }

    /**
     * 주간 리포트 생성 작업
     */
    @Bean
    public Job weeklyReportJob() {
        return new JobBuilder("weeklyReportJob", jobRepository)
            .incrementer(new RunIdIncrementer())
            .listener(new JobExecutionListener())
            .start(weeklyStatsAggregationStep())
            .next(reportGenerationStep())
            .next(reportDistributionStep())
            .build();
    }

    /**
     * 주간 통계 집계 스텝
     */
    @Bean
    public Step weeklyStatsAggregationStep() {
        return new StepBuilder("weeklyStatsAggregationStep", jobRepository)
            .<RawStatsData, AggregatedStatsData>chunk(500, transactionManager)
            .reader(rawStatsDataReader())
            .processor(statsAggregationProcessor())
            .writer(aggregatedStatsDataWriter())
            .build();
    }

    /**
     * 리포트 생성 스텝
     */
    @Bean
    public Step reportGenerationStep() {
        return new StepBuilder("reportGenerationStep", jobRepository)
            .tasklet(new ReportGenerationTasklet(), transactionManager)
            .build();
    }

    /**
     * 리포트 배포 스텝
     */
    @Bean
    public Step reportDistributionStep() {
        return new StepBuilder("reportDistributionStep", jobRepository)
            .tasklet(new ReportDistributionTasklet(), transactionManager)
            .build();
    }

    // ========== 데이터 리더들 ==========

    /**
     * 로그 데이터 리더
     */
    @Bean
    public RepositoryItemReader<LogData> logDataReader() {
        return new RepositoryItemReaderBuilder<LogData>()
            .name("logDataReader")
            // .repository(attackLogRepository)  // 실제 구현에서 주입
            .methodName("findOldLogs")
            .pageSize(1000)
            .arguments(LocalDateTime.now().minusDays(7)) // 7일 이전 데이터
            .sorts(Collections.singletonMap("timestamp", Sort.Direction.ASC))
            .build();
    }

    /**
     * 원시 통계 데이터 리더
     */
    @Bean
    public RepositoryItemReader<RawStatsData> rawStatsDataReader() {
        return new RepositoryItemReaderBuilder<RawStatsData>()
            .name("rawStatsDataReader")
            // .repository(statsRepository)  // 실제 구현에서 주입
            .methodName("findWeeklyData")
            .pageSize(500)
            .arguments(
                LocalDateTime.now().minusDays(7),
                LocalDateTime.now()
            )
            .sorts(Collections.singletonMap("timestamp", Sort.Direction.ASC))
            .build();
    }

    // ========== 데이터 프로세서들 ==========

    /**
     * 로그 아카이브 프로세서
     */
    @Bean
    public ItemProcessor<LogData, ArchivedLogData> logArchiveProcessor() {
        return new ItemProcessor<LogData, ArchivedLogData>() {
            @Override
            public ArchivedLogData process(LogData item) throws Exception {
                log.debug("Archiving log: {}", item.getId());

                // 로그 데이터를 아카이브 형태로 변환
                ArchivedLogData archived = new ArchivedLogData();
                archived.setOriginalId(item.getId());
                archived.setTimestamp(item.getTimestamp());
                archived.setCompressedData(compressLogData(item));
                archived.setArchiveDate(LocalDateTime.now());

                return archived;
            }

            private String compressLogData(LogData logData) {
                // 로그 데이터 압축 로직 (실제로는 GZIP 등 사용)
                return "compressed_" + logData.toString();
            }
        };
    }

    /**
     * 통계 집계 프로세서
     */
    @Bean
    public ItemProcessor<RawStatsData, AggregatedStatsData> statsAggregationProcessor() {
        return new ItemProcessor<RawStatsData, AggregatedStatsData>() {
            @Override
            public AggregatedStatsData process(RawStatsData item) throws Exception {
                log.debug("Processing stats: {}", item.getId());

                // 통계 데이터 집계
                AggregatedStatsData aggregated = new AggregatedStatsData();
                aggregated.setTimeWindow(item.getTimeWindow());
                aggregated.setTotalRequests(calculateTotalRequests(item));
                aggregated.setTotalAttacks(calculateTotalAttacks(item));
                aggregated.setAverageResponseTime(calculateAverageResponseTime(item));
                aggregated.setTopAttackTypes(getTopAttackTypes(item));

                return aggregated;
            }

            private long calculateTotalRequests(RawStatsData data) {
                // 실제 집계 로직
                return data.getRequestCount();
            }

            private long calculateTotalAttacks(RawStatsData data) {
                // 실제 집계 로직
                return data.getAttackCount();
            }

            private double calculateAverageResponseTime(RawStatsData data) {
                // 실제 집계 로직
                return data.getResponseTime();
            }

            private String getTopAttackTypes(RawStatsData data) {
                // 실제 집계 로직
                return data.getTopAttackType();
            }
        };
    }

    // ========== 데이터 라이터들 ==========

    /**
     * 아카이브 데이터 라이터
     */
    @Bean
    public RepositoryItemWriter<ArchivedLogData> archivedLogDataWriter() {
        return new RepositoryItemWriterBuilder<ArchivedLogData>()
            .repository(null) // 실제 구현에서는 ArchivedLogRepository 주입
            .build();
    }

    /**
     * 집계 통계 데이터 라이터
     */
    @Bean
    public RepositoryItemWriter<AggregatedStatsData> aggregatedStatsDataWriter() {
        return new RepositoryItemWriterBuilder<AggregatedStatsData>()
            .repository(null) // 실제 구현에서는 AggregatedStatsRepository 주입
            .build();
    }

    // ========== 스케줄링 설정 ==========

    /**
     * 일일 로그 정리 작업 스케줄링 (매일 새벽 2시)
     */
    @Scheduled(cron = "0 0 2 * * *")
    public void scheduleDailyLogCleanup() {
        log.info("Starting scheduled daily log cleanup job");
        try {
            // JobLauncher를 통한 배치 작업 실행
            // jobLauncher.run(logCleanupJob(), new JobParameters());
            log.info("Daily log cleanup job completed successfully");
        } catch (Exception e) {
            log.error("Failed to execute daily log cleanup job", e);
        }
    }

    /**
     * 주간 리포트 생성 스케줄링 (매주 월요일 오전 6시)
     */
    @Scheduled(cron = "0 0 6 * * MON")
    public void scheduleWeeklyReport() {
        log.info("Starting scheduled weekly report generation job");
        try {
            // JobLauncher를 통한 배치 작업 실행
            // jobLauncher.run(weeklyReportJob(), new JobParameters());
            log.info("Weekly report generation job completed successfully");
        } catch (Exception e) {
            log.error("Failed to execute weekly report generation job", e);
        }
    }

    /**
     * 실시간 통계 업데이트 (매 5분마다)
     */
    @Scheduled(fixedRate = 300000) // 5분
    public void updateRealTimeStats() {
        log.debug("Updating real-time statistics");
        try {
            // 실시간 통계 업데이트 로직
            updateCurrentStats();
            log.debug("Real-time statistics updated successfully");
        } catch (Exception e) {
            log.error("Failed to update real-time statistics", e);
        }
    }

    private void updateCurrentStats() {
        // 실시간 통계 업데이트 구현
        // Redis에서 현재 통계 조회 및 업데이트
    }

    // ========== 배치 작업 리스너 ==========

    /**
     * 배치 작업 실행 리스너
     */
    public static class JobExecutionListener implements org.springframework.batch.core.JobExecutionListener {

        @Override
        public void beforeJob(org.springframework.batch.core.JobExecution jobExecution) {
            log.info("Starting batch job: {} at {}",
                jobExecution.getJobInstance().getJobName(),
                jobExecution.getStartTime());
        }

        @Override
        public void afterJob(org.springframework.batch.core.JobExecution jobExecution) {
            log.info("Batch job: {} completed with status: {} in {}ms",
                jobExecution.getJobInstance().getJobName(),
                jobExecution.getStatus(),
                jobExecution.getEndTime().getTime() - jobExecution.getStartTime().getTime());

            // 배치 작업 결과 메트릭 기록
            if (jobExecution.getStatus() == org.springframework.batch.core.BatchStatus.COMPLETED) {
                log.info("Batch job completed successfully");
            } else if (jobExecution.getStatus() == org.springframework.batch.core.BatchStatus.FAILED) {
                log.error("Batch job failed: {}", jobExecution.getAllFailureExceptions());
            }
        }
    }

    // ========== 데이터 클래스들 (DTO) ==========

    public static class LogData {
        private String id;
        private LocalDateTime timestamp;
        private String data;

        // getters and setters
        public String getId() { return id; }
        public void setId(String id) { this.id = id; }
        public LocalDateTime getTimestamp() { return timestamp; }
        public void setTimestamp(LocalDateTime timestamp) { this.timestamp = timestamp; }
        public String getData() { return data; }
        public void setData(String data) { this.data = data; }

        @Override
        public String toString() { return "LogData{id='" + id + "', timestamp=" + timestamp + "}"; }
    }

    public static class ArchivedLogData {
        private String originalId;
        private LocalDateTime timestamp;
        private String compressedData;
        private LocalDateTime archiveDate;

        // getters and setters
        public String getOriginalId() { return originalId; }
        public void setOriginalId(String originalId) { this.originalId = originalId; }
        public LocalDateTime getTimestamp() { return timestamp; }
        public void setTimestamp(LocalDateTime timestamp) { this.timestamp = timestamp; }
        public String getCompressedData() { return compressedData; }
        public void setCompressedData(String compressedData) { this.compressedData = compressedData; }
        public LocalDateTime getArchiveDate() { return archiveDate; }
        public void setArchiveDate(LocalDateTime archiveDate) { this.archiveDate = archiveDate; }
    }

    public static class RawStatsData {
        private String id;
        private String timeWindow;
        private long requestCount;
        private long attackCount;
        private double responseTime;
        private String topAttackType;

        // getters and setters
        public String getId() { return id; }
        public void setId(String id) { this.id = id; }
        public String getTimeWindow() { return timeWindow; }
        public void setTimeWindow(String timeWindow) { this.timeWindow = timeWindow; }
        public long getRequestCount() { return requestCount; }
        public void setRequestCount(long requestCount) { this.requestCount = requestCount; }
        public long getAttackCount() { return attackCount; }
        public void setAttackCount(long attackCount) { this.attackCount = attackCount; }
        public double getResponseTime() { return responseTime; }
        public void setResponseTime(double responseTime) { this.responseTime = responseTime; }
        public String getTopAttackType() { return topAttackType; }
        public void setTopAttackType(String topAttackType) { this.topAttackType = topAttackType; }
    }

    public static class AggregatedStatsData {
        private String timeWindow;
        private long totalRequests;
        private long totalAttacks;
        private double averageResponseTime;
        private String topAttackTypes;

        // getters and setters
        public String getTimeWindow() { return timeWindow; }
        public void setTimeWindow(String timeWindow) { this.timeWindow = timeWindow; }
        public long getTotalRequests() { return totalRequests; }
        public void setTotalRequests(long totalRequests) { this.totalRequests = totalRequests; }
        public long getTotalAttacks() { return totalAttacks; }
        public void setTotalAttacks(long totalAttacks) { this.totalAttacks = totalAttacks; }
        public double getAverageResponseTime() { return averageResponseTime; }
        public void setAverageResponseTime(double averageResponseTime) { this.averageResponseTime = averageResponseTime; }
        public String getTopAttackTypes() { return topAttackTypes; }
        public void setTopAttackTypes(String topAttackTypes) { this.topAttackTypes = topAttackTypes; }
    }

    // ========== Tasklet 구현체들 ==========

    public static class OldLogDeletionTasklet implements org.springframework.batch.core.step.tasklet.Tasklet {
        @Override
        public org.springframework.batch.repeat.RepeatStatus execute(
                org.springframework.batch.core.StepContribution contribution,
                org.springframework.batch.core.scope.context.ChunkContext chunkContext) {

            log.info("Executing old log deletion tasklet");

            // 30일 이전 로그 삭제 로직
            LocalDateTime cutoffDate = LocalDateTime.now().minusDays(30);

            try {
                // 실제 구현에서는 Repository를 통한 삭제
                int deletedCount = deleteOldLogs(cutoffDate);
                log.info("Deleted {} old log entries", deletedCount);

                contribution.incrementWriteCount(deletedCount);
                return org.springframework.batch.repeat.RepeatStatus.FINISHED;

            } catch (Exception e) {
                log.error("Error deleting old logs", e);
                throw new RuntimeException("Failed to delete old logs", e);
            }
        }

        private int deleteOldLogs(LocalDateTime cutoffDate) {
            // 실제 삭제 로직
            return 100; // 예시 값
        }
    }

    public static class StatisticsUpdateTasklet implements org.springframework.batch.core.step.tasklet.Tasklet {
        @Override
        public org.springframework.batch.repeat.RepeatStatus execute(
                org.springframework.batch.core.StepContribution contribution,
                org.springframework.batch.core.scope.context.ChunkContext chunkContext) {

            log.info("Executing statistics update tasklet");

            try {
                // 통계 데이터 업데이트 로직
                updateDailyStatistics();
                updateWeeklyStatistics();
                updateMonthlyStatistics();

                return org.springframework.batch.repeat.RepeatStatus.FINISHED;

            } catch (Exception e) {
                log.error("Error updating statistics", e);
                throw new RuntimeException("Failed to update statistics", e);
            }
        }

        private void updateDailyStatistics() {
            log.debug("Updating daily statistics");
        }

        private void updateWeeklyStatistics() {
            log.debug("Updating weekly statistics");
        }

        private void updateMonthlyStatistics() {
            log.debug("Updating monthly statistics");
        }
    }

    public static class ReportGenerationTasklet implements org.springframework.batch.core.step.tasklet.Tasklet {
        @Override
        public org.springframework.batch.repeat.RepeatStatus execute(
                org.springframework.batch.core.StepContribution contribution,
                org.springframework.batch.core.scope.context.ChunkContext chunkContext) {

            log.info("Executing report generation tasklet");

            try {
                // 리포트 생성 로직
                generateSecurityReport();
                generatePerformanceReport();
                generateUsageReport();

                return org.springframework.batch.repeat.RepeatStatus.FINISHED;

            } catch (Exception e) {
                log.error("Error generating reports", e);
                throw new RuntimeException("Failed to generate reports", e);
            }
        }

        private void generateSecurityReport() {
            log.debug("Generating security report");
        }

        private void generatePerformanceReport() {
            log.debug("Generating performance report");
        }

        private void generateUsageReport() {
            log.debug("Generating usage report");
        }
    }

    public static class ReportDistributionTasklet implements org.springframework.batch.core.step.tasklet.Tasklet {
        @Override
        public org.springframework.batch.repeat.RepeatStatus execute(
                org.springframework.batch.core.StepContribution contribution,
                org.springframework.batch.core.scope.context.ChunkContext chunkContext) {

            log.info("Executing report distribution tasklet");

            try {
                // 리포트 배포 로직
                distributeReportsToAdmins();
                uploadReportsToCloud();

                return org.springframework.batch.repeat.RepeatStatus.FINISHED;

            } catch (Exception e) {
                log.error("Error distributing reports", e);
                throw new RuntimeException("Failed to distribute reports", e);
            }
        }

        private void distributeReportsToAdmins() {
            log.debug("Distributing reports to administrators");
        }

        private void uploadReportsToCloud() {
            log.debug("Uploading reports to cloud storage");
        }
    }
}